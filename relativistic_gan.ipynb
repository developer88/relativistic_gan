{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relativistic GAN\n",
    "\n",
    "ℹ️ Based on the work of [eriklindernoren](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/relativistic_gan/relativistic_gan.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:07.821144Z",
     "start_time": "2020-12-06T17:26:07.798182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "dataroot = 'dataset/'\n",
    "dataset_name = 'dog_photos' # e.g `dataroot/dataset_name`\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 60\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "# This setting is not actually usable as you need to manually adjust the\n",
    "#   architecture of the models in case you wish to use a different image size\n",
    "image_size =  256\n",
    "img_size = image_size\n",
    "hr_height = image_size\n",
    "hr_width = image_size\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "channels = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "latent_dim = 100\n",
    "\n",
    "# Number of training epochs\n",
    "n_epochs = 9000\n",
    "\n",
    "# start with epoch\n",
    "# time to time during the training the model state will be saved into `models` folder\n",
    "# in case you need to break the execution adjust this value with the number of the last epochs\n",
    "#   to continue where you left of last time.\n",
    "start_with_epoch = 0\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta hyperparams for Adam optimizers\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "# processing settings\n",
    "save_state_each = 1 # save models state every / epochs\n",
    "save_image_each = 2 # save intermediate result every / epochs\n",
    "check_alive_every = 3 # display loss information every / epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.597783Z",
     "start_time": "2020-12-06T17:26:07.850433Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.611035Z",
     "start_time": "2020-12-06T17:26:09.600911Z"
    }
   },
   "outputs": [],
   "source": [
    "# create folders\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.634603Z",
     "start_time": "2020-12-06T17:26:09.616732Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.654895Z",
     "start_time": "2020-12-06T17:26:09.637454Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_shape = (hr_height, hr_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.674542Z",
     "start_time": "2020-12-06T17:26:09.667483Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkpoint(name, data, epoch_num):\n",
    "    torch.save(data, '%s/%s_epoch_%s.pth' % ('./model', name, epoch_num))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.701934Z",
     "start_time": "2020-12-06T17:26:09.683390Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:09.738182Z",
     "start_time": "2020-12-06T17:26:09.730056Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "#[transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# save some resources\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:10.578482Z",
     "start_time": "2020-12-06T17:26:09.749419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "if start_with_epoch != 0:\n",
    "    print(\"load previous state\")\n",
    "    generator.load_state_dict(torch.load(\"./model/relativ_gan_gen_epoch_%d.pth\" % start_with_epoch, map_location=device))\n",
    "    discriminator.load_state_dict(torch.load(\"./model/relativ_gan_disc_epoch_%d.pth\" % start_with_epoch, map_location=device))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:30:37.939796Z",
     "start_time": "2020-12-06T17:30:15.096860Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "print('Training')\n",
    "for epoch in range(start_with_epoch, n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        real_pred = discriminator(real_imgs).detach()\n",
    "        fake_pred = discriminator(gen_imgs)\n",
    "        \n",
    "        g_loss = adversarial_loss(fake_pred - real_pred.mean(0, keepdim=True), valid)\n",
    "        # for normal\n",
    "        # g_loss = adversarial_loss(fake_pred - real_pred, valid)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Predict validity\n",
    "        real_pred = discriminator(real_imgs)\n",
    "        fake_pred = discriminator(gen_imgs.detach())\n",
    "        \n",
    "        real_loss = adversarial_loss(real_pred - fake_pred.mean(0, keepdim=True), valid)\n",
    "        fake_loss = adversarial_loss(fake_pred - real_pred.mean(0, keepdim=True), fake)\n",
    "        \n",
    "        # for normal\n",
    "        # real_loss = adversarial_loss(real_pred - fake_pred, valid)\n",
    "        # fake_loss = adversarial_loss(fake_pred - real_pred, fake)\n",
    "        \n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % save_image_each == 0:\n",
    "            print('save image')\n",
    "            save_image(gen_imgs.data[:25], \"images/relativ_gan_%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "            \n",
    "        if batches_done % check_alive_every == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            \n",
    "        if batches_done % save_state_each == 0:\n",
    "            print('save checkpoint')\n",
    "            checkpoint('relativ_gan_gen', generator.state_dict(), epoch)\n",
    "            checkpoint('relativ_gan_disc', discriminator.state_dict(), epoch)\n",
    "            \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "checkpoint('relativ_gan_gen', generator.state_dict(), 'final')\n",
    "checkpoint('relativ_gan_disc', discriminator.state_dict(), 'final')      \n",
    "\n",
    "print('finish')\n",
    "save_image(gen_imgs.data[:25], \"images/relativ_gan_final.png\", nrow=5, normalize=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T17:26:37.790112Z",
     "start_time": "2020-12-06T17:26:37.775870Z"
    }
   },
   "outputs": [],
   "source": [
    "# just in case we need to interrupt and save the results manually from the current memory\n",
    "#checkpoint('relativ_gan_gen', generator.state_dict(), EPOCH_NUMBER_HERE)\n",
    "#checkpoint('relativ_gan_disc', discriminator.state_dict(), EPOCH_NUMBER_HERE)\n",
    "#save_image(gen_imgs.data[:25], \"images/relativ_gan_epoch_%d.png\" % EPOCH_NUMBER_HERE, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
